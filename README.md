# snowflake-spark-connector

In this example, the code uses snowflake-spark-connector and snowflake-jdbc driver to connect to a snowflake database from spark and perform some processing.

## Create an EMR cluster
Version used: 5.30.0 with Spark 2.4.5 and Scala 2.11.12

## Download the latest snowflake-spark-connector and snowflake-jdbc drivers
For this example, I downloaded the latest snowflake-spark-connector and snowflake-jdbc driver jars on to the EMR cluster.

We could also refer to the corresponding packages from the maven repository

## Spark Command line interface for development
For this example, I used the Spark command line interface with Scala, by issuing :

    spark-shell --jars snowflake-jdbc-3.12.8.jar,spark-snowflake_2.11-2.8.0-spark_2.4.jar

## Walk-through of the example

This example reads a partitioned directory structure of parquet files (of movie ratings and preferences) in an S3 bucket, generated by another Spark job.

This example assumes an empty table (movies) existing already in the Snowflake database.

The code inserts the data from S3 into the snowflake database table. 

The detail within the Snowflake taking place during the invocation of "save()" function  will be added at a later point in time.

Post inserting data, the code reads specific data range from Snowflake and prints it using the dataframe.show() function.
